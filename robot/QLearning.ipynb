{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np   # q(s,a)를 numpy array 형태로 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Direct_Symbols = ['←', '↑', '→', '↓']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (526239952.py, line 59)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31melif self.x==3 and self.y==3\u001b[39m\n                                ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m expected ':'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class GridWorld():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.walls = set([\n",
    "            (3, 2), (4, 2), (2, 2),    \n",
    "            (1, 4), (1, 5), (4, 3), (1,6) ])\n",
    "        self.reset()\n",
    "\n",
    "    def step(self, a):\n",
    "        old_x, old_y = self.x, self.y\n",
    "\n",
    "        if a == 0:   self.move_left()\n",
    "        elif a == 1: self.move_up()\n",
    "        elif a == 2: self.move_right()\n",
    "        elif a == 3: self.move_down()\n",
    "\n",
    "        if (self.x, self.y) in self.walls:\n",
    "            self.x, self.y = old_x, old_y\n",
    "\n",
    "        reward = -1\n",
    "        done = self.is_done()\n",
    "        return (self.x, self.y), reward, done\n",
    "\n",
    "    def move_left(self):  \n",
    "        if self.y==0:\n",
    "            pass\n",
    "        elif self.y==3 and self.x in [2,3]:\n",
    "            pass\n",
    "        elif self.y==4 and self.x==4:\n",
    "            pass\n",
    "        else:\n",
    "            self.y -= 1\n",
    "\n",
    "    def move_right(self):\n",
    "        if self.y==1 and self.x in [2,3,4]:\n",
    "            pass\n",
    "        elif self.y==3 and self.x==1:\n",
    "            pass\n",
    "        elif self.y==6:\n",
    "            pass\n",
    "        else:\n",
    "            self.y += 1\n",
    "      \n",
    "    def move_up(self):\n",
    "        if self.x==0:\n",
    "            pass\n",
    "        elif self.x==2 and self.y in [4,5,6]:\n",
    "            pass\n",
    "        else:\n",
    "            self.x -= 1\n",
    "\n",
    "    def move_down(self):\n",
    "        if self.x==4:\n",
    "            pass\n",
    "        elif self.x==0 and self.y in [4,5,6]:\n",
    "            pass\n",
    "        elif self.x==1 and self.y==2:\n",
    "            pass\n",
    "        elif self.x==3 and self.y==3:\n",
    "            pass\n",
    "        else:\n",
    "            self.x+=1\n",
    "\n",
    "    def is_done(self):\n",
    "        return (self.x, self.y) == (4, 6)\n",
    "\n",
    "    def reset(self):\n",
    "        self.x, self.y = 2, 0\n",
    "        return (self.x, self.y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAgent():\n",
    "    def __init__(self):\n",
    "        self.q_table = np.zeros((5, 7, 4)) # Q 테이블을 0으로 초기화\n",
    "        self.eps = 0.9\n",
    "\n",
    "    def select_action(self, s):       # eps-greedy로 액션을 선택해준다\n",
    "                                      # 𝜖 확률로 새로운 무작위 행동을 선택(탐험)하고, (1- 𝜖) 확률로 현재 상태에서 최선의 행동을 선택\n",
    "        x, y = s\n",
    "        coin = random.random()\n",
    "        if coin < self.eps:\n",
    "            action = random.randint(0,3)\n",
    "        else:\n",
    "            action_val = self.q_table[x,y,:]\n",
    "            action = np.argmax(action_val)\n",
    "        return action\n",
    "\n",
    "    def update_table(self, transition):\n",
    "        s, a, r, s_prime = transition\n",
    "        x,y = s\n",
    "        next_x, next_y = s_prime\n",
    "        a_prime = self.select_action(s_prime) # S'에서 선택할 액션 (실제로 취한 액션이 아님)\n",
    "        \n",
    "             # Q러닝 업데이트 식을 이용 ,  학습률(𝜌) = 0.1 ,   할인율(𝛾) = 1\n",
    "        self.q_table[x,y,a] = self.q_table[x,y,a] + 0.1 * (r + np.amax(self.q_table[next_x,next_y,:]) - self.q_table[x,y,a])\n",
    "\n",
    "    def anneal_eps(self):\n",
    "        self.eps -= 0.01  # Q러닝에선 epsilon 이 좀더 천천히 줄어 들도록 함.\n",
    "        self.eps = max(self.eps, 0.2) \n",
    "   \n",
    "\n",
    "    def show_table(self):\n",
    "        q_lst = self.q_table.tolist()\n",
    "        data = np.zeros((5,7))\n",
    "        for row_idx in range(len(q_lst)):\n",
    "            row = q_lst[row_idx]\n",
    "            for col_idx in range(len(row)):\n",
    "                col = row[col_idx]\n",
    "                action = np.argmax(col)\n",
    "                data[row_idx, col_idx] = action\n",
    "        print(data)\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_policy(agent, env):\n",
    "    for i in range(5):\n",
    "        row = []\n",
    "        for j in range(7):\n",
    "            if (i,j) in env.walls:\n",
    "                row.append(' ')                    \n",
    "            elif (i,j) == (4,6):\n",
    "                row.append('G')                    \n",
    "            else:\n",
    "                a = np.argmax(agent.q_table[i,j,:])\n",
    "                row.append(Direct_Symbols[a])      \n",
    "        print(' '.join(row))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     21\u001b[39m     agent.show_table()\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     10\u001b[39m     a = agent.select_action(s)\n\u001b[32m     11\u001b[39m     s_prime, r, done = env.step(a)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43ms_prime\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# 한 스텝이 끝날때마다 update table 함수 호출\u001b[39;00m\n\u001b[32m     13\u001b[39m     s = s_prime\n\u001b[32m     14\u001b[39m agent.anneal_eps()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mQAgent.update_table\u001b[39m\u001b[34m(self, transition)\u001b[39m\n\u001b[32m     21\u001b[39m a_prime = \u001b[38;5;28mself\u001b[39m.select_action(s_prime) \u001b[38;5;66;03m# S'에서 선택할 액션 (실제로 취한 액션이 아님)\u001b[39;00m\n\u001b[32m     23\u001b[39m      \u001b[38;5;66;03m# Q러닝 업데이트 식을 이용 ,  학습률(𝜌) = 0.1 ,   할인율(𝛾) = 1\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28mself\u001b[39m.q_table[x,y,a] = \u001b[38;5;28mself\u001b[39m.q_table[x,y,a] + \u001b[32m0.1\u001b[39m * (r + \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mamax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mq_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnext_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnext_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m - \u001b[38;5;28mself\u001b[39m.q_table[x,y,a])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EWHA/venv/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:3181\u001b[39m, in \u001b[36mamax\u001b[39m\u001b[34m(a, axis, out, keepdims, initial, where)\u001b[39m\n\u001b[32m   3168\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_max_dispatcher)\n\u001b[32m   3169\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mamax\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=np._NoValue, initial=np._NoValue,\n\u001b[32m   3170\u001b[39m          where=np._NoValue):\n\u001b[32m   3171\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3172\u001b[39m \u001b[33;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[32m   3173\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3179\u001b[39m \u001b[33;03m    ndarray.max : equivalent method\u001b[39;00m\n\u001b[32m   3180\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3181\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmax\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3182\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EWHA/venv/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:86\u001b[39m, in \u001b[36m_wrapreduction\u001b[39m\u001b[34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     84\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis=axis, out=out, **passkwargs)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    env = GridWorld()\n",
    "    agent = QAgent()\n",
    "\n",
    "    for n_epi in range(1000):\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            a = agent.select_action(s)\n",
    "            s_prime, r, done = env.step(a)\n",
    "            agent.update_table((s,a,r,s_prime))   # 한 스텝이 끝날때마다 update table 함수 호출\n",
    "            s = s_prime\n",
    "        agent.anneal_eps()\n",
    "\n",
    "        # ── 여기에 출력 코드 추가 ──\n",
    "        if n_epi % 100 == 0 and (n_epi // 100) <= 8:\n",
    "            print(f\"--- Episode {n_epi} ---\")\n",
    "            print_policy(agent, env)\n",
    "\n",
    "    agent.show_table()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld():\n",
    "    def __init__(self):\n",
    "        self.x=0\n",
    "        self.y=0\n",
    "    \n",
    "    def step(self, a):\n",
    "        # 0번 액션: 왼쪽, 1번 액션: 위, 2번 액션: 오른쪽, 3번 액션: 아래쪽\n",
    "        if a==0:\n",
    "            self.move_left()\n",
    "        elif a==1:\n",
    "            self.move_up()\n",
    "        elif a==2:\n",
    "            self.move_right()\n",
    "        elif a==3:\n",
    "            self.move_down()\n",
    "\n",
    "        reward = -1  # 보상은 항상 -1로 고정\n",
    "        done = self.is_done()\n",
    "        return (self.x, self.y), reward, done\n",
    "\n",
    "    def move_left(self):  # 벽에 막혀 있을 때, 벽의 방향으로 진행하는 액션은 모두 무효 처리\n",
    "        if self.y==0:\n",
    "            pass\n",
    "        elif self.y==3 and self.x in [0,1,2]:\n",
    "            pass\n",
    "        elif self.y==5 and self.x in [2,3,4]:\n",
    "            pass\n",
    "        else:\n",
    "            self.y -= 1\n",
    "\n",
    "    def move_right(self):\n",
    "        if self.y==1 and self.x in [0,1,2]:\n",
    "            pass\n",
    "        elif self.y==3 and self.x in [2,3,4]:\n",
    "            pass\n",
    "        elif self.y==6:\n",
    "            pass\n",
    "        else:\n",
    "            self.y += 1\n",
    "      \n",
    "    def move_up(self):\n",
    "        if self.x==0:\n",
    "            pass\n",
    "        elif self.x==3 and self.y==2:\n",
    "            pass\n",
    "        else:\n",
    "            self.x -= 1\n",
    "\n",
    "    def move_down(self):\n",
    "        if self.x==4:\n",
    "            pass\n",
    "        elif self.x==1 and self.y==4:\n",
    "            pass\n",
    "        else:\n",
    "            self.x+=1\n",
    "\n",
    "    def is_done(self):\n",
    "        if self.x==4 and self.y==6: # 목표 지점인 (4,6)에 도달하면 끝난다\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "      \n",
    "    def reset(self):\n",
    "        self.x = 0\n",
    "        self.y = 0\n",
    "        return (self.x, self.y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
